
üè° House Price Prediction ‚Äì Kaggle Competition
RMSE: 0.13371 | Rank: 1,554 out of ~5,000+ participants

Developed an end-to-end regression model to predict housing prices using the Ames Housing dataset in a Kaggle competition. Preprocessed raw data, performed feature engineering, and implemented hyperparameter-tuned XGBoost models to minimize Root Mean Squared Error (RMSE). Achieved a final score of 0.13371, placing in the top 30% globally.

Key Contributions:

Handled missing data, encoded categorical variables, and normalized skewed features.

Applied log transformation to improve model stability and accuracy.

Used RandomizedSearchCV with cross-validation to optimize XGBoost hyperparameters.

Built a clean submission pipeline using pandas and scikit-learn.

Gained hands-on experience with real-world regression problems and model evaluation.

Tools & Technologies: Python, Pandas, NumPy, XGBoost, Scikit-learn, Matplotlib, Google Colab, Kaggle
